import os, re, sys, glob
SNAKEMAKE_RULE_DIR='../snakemake-workflows'

OPT_DIR=config['system_paths']['opt_dir']
BIN_DIR=config['system_paths']['bin_dir']
sys.path.append("%s/py-metagenomics" % (OPT_DIR))
from edl.illumina import get_barcodes_and_chemistry

def set_binary_path(binary,paths):
    if binary not in config['system_paths']:
        for path in paths:
            binary_full_path=os.path.join(path,binary)
            if os.path.exists(binary_full_path):
                config["system_paths"][binary]=binary_full_path
                break
        else:
            config["system_paths"][binary]=binary

binaries=['miraconvert','seqtk','createPrimerFile.py','prinseq']
for binary in binaries:
    set_binary_path(binary,[BIN_DIR,OPT_DIR])

cleaned_reads='reads.cleaned.fastq'
skip_trim = config.setdefault("skip_trim","False")=="True"

for i, sample in enumerate(config['inputs']):
    sample_data=config['inputs'][sample]
    barcodes,chemistry = get_barcodes_and_chemistry(sample_data['sample_sheet'],
                                              sample_data['sample_num'])
    sample_data['barcodes']=' '.join(barcodes)
    sample_data['primer_template']=glob.glob(OPT_DIR + "/py-metagenomics/primerTemplates/" + chemistry + ".*primers.fasta")[-1] 

rule all:
    input:
        expand("{sample}/reads.raw.stats",sample=config['inputs'].keys()),
        "spades/contigs.fasta",
        "contigs.stats"

rule rename_forward_reads:
    """
    Rename reads to be based on a "sample" name
    """
    input:
        lambda wildcards: config['inputs'][wildcards.sample]['forward_reads']
    output:
        temp("{sample}/R1.renamed.fastq"),
        temp("{sample}/R1.renamed.fastq.log")
    shell:
        "{config[system_paths][miraconvert]} -f fastq -R {wildcards.sample} -S solexa -t fastq {input} {output[0]} > {output[1]}"

rule rename_reverse_reads:
    """
    Rename reads to be based on a "sample" name
    """
    input:
        lambda wildcards: config['inputs'][wildcards.sample]['reverse_reads']
    output:
        temp("{sample}/R2.renamed.fastq"),
        temp("{sample}/R2.renamed.fastq.log")
    shell:
        "{config[system_paths][miraconvert]} -f fastq -R {wildcards.sample} -S solexa -t fastq {input} {output[0]} > {output[1]}"

rule interleave:
    """
    Interleave forward and reverse reads while reanaming
    """
    input:
        "{sample}/R1.renamed.fastq",
        "{sample}/R2.renamed.fastq"
    output:
        "{sample}/reads.raw.fastq"
    shell:
        "{config[system_paths][seqtk]} mergepe {input} > {output}"

rule merge_interleaved:
    """
    Combine all interleaved raw reads files into one for no-trim assembly
    """
    input:
        expand("{sample}/reads.raw.fastq", sample=config['inputs'])
    output:
        "reads.raw.fastq"
    shell:
        "cat {input} > {output}"

rule trimming_adapters:
    """
    GEnerates fasta file with adapters for trimming
    """
    input:
        lambda wildcards: config['inputs'][wildcards.sample]['sample_sheet']
    output:
        "{sample}/adapters.fa"
    params:
        barcodes = \
         lambda wildcards: config["inputs"][wildcards.sample]['barcodes'],
        primer_template = \
         lambda wildcards: config["inputs"][wildcards.sample]['primer_template']
    shell:
        "{config[system_paths][createPrimerFile.py]} {params.primer_template} {params.barcodes} > {output}"

rule trimmomatic_pe:
    """Trims given paired-end reads with given parameters"""
    input:
        "{sample}/R1.renamed.fastq",
        "{sample}/R2.renamed.fastq",
        "{sample}/adapters.fa"
    output:
        "{sample}/trimmed_1P.fastq.gz",
        "{sample}/trimmed_2P.fastq.gz",
        "{sample}/trimmed_1U.fastq.gz",
        "{sample}/trimmed_2U.fastq.gz",
        "{sample}/trimmed.fasta.log"
    params:
        trim_params=lambda wildcards: config['trimmomatic_params'] % \
            ("%s/adapters.fa" % (wildcards.sample))
    shell:
        """
        time java -jar {config[system_paths][trimmomatic_jar]} PE \
            {input[0]} {input[1]} \
            {output[0]} {output[2]} {output[1]} {output[3]} \
            {params.trim_params} 2> {output[4]}
        """

rule merge_trimmed:
    """
    Mrege the trimmed output of all samples into a single file
    """
    input:
        expand([
            "{sample}/trimmed_1P.fastq.gz",
            "{sample}/trimmed_2P.fastq.gz",
            "{sample}/trimmed_1U.fastq.gz",
            "{sample}/trimmed_2U.fastq.gz"], sample=config['inputs'])
    output:
        "reads.trimmed.paired.fastq.gz",
        "reads.trimmed.unpaired.fastq.gz"
    shell:
        '\n'.join( \
        ["rm -f {output[0]} {output[1]}",] + \
        ["{config[system_paths][seqtk]} mergepe \
          %s/trimmed_1P.fastq.gz %s/trimmed_2P.fastq.gz | \
          gzip -c >> {output[0]}" % (sample, sample) \
           for sample in config['inputs']] + \
        ["gunzip -c %s/trimmed_1U.fastq.gz %s/trimmed_2U.fastq.gz |\
          gzip -c >> {output[1]}" % (sample, sample) \
           for sample in config['inputs']]
               )

if not skip_trim:
    spades_input = [
        "reads.trimmed.paired.fastq.gz",
        "reads.trimmed.unpaired.fastq.gz"]
else:
    print ("No triming!")
    spades_input = "reads.raw.fastq"

rule run_spades:
    """
    $(CONTIGS_LOCAL): $(R1_FASTQ) $(R2_FASTQ) | $(OUTPUT_DIR)
        $(SPADES) -m $(SPADES_RAM) -o $(OUTPUT_DIR)/spades --pe1-1 $(R1_FASTQ) --   pe1-2 $(R2_FASTQ) --only-assembler --meta
    """
    input:
        spades_input
    output:
        "spades/contigs.fasta"
    params:
        ram_limit=config['spades']['ram'],
        spades_flags="" if skip_trim else "--only-assembler",
        input_flags="--pe1-12 %s" % (spades_input) if skip_trim \
            else "--pe1-12 %s --pe1-s %s" % (spades_input[0],\
                                             spades_input[1])
    shell:
        """
        python {config[system_paths][spades.py]} -m {params.ram_limit} -o spades {params.input_flags} {params.spades_flags} --meta
        """

rule contigs_fasta:
    """
    Crate a link to contigs.fasta a the top level
    """
    input:
        "spades/contigs.fasta"
    output:
        "contigs.fasta"
    shell:
        "ln {input} {output}"

rule prinseq_fasta:
    """ calculate basic stats for a fasta file """
    input:
        "{file_root}.fasta"
    output:
        "{file_root}.stats"
    shell:
        "{config[system_paths][prinseq]} -fasta {input} -stats_len -stats_info > {output}"

rule prinseq_fastq:
    """ calculate basic stats for a fastq file """
    input:
        "{file_root}.fastq"
    output:
        "{file_root}.stats"
    shell:
        "{config[system_paths][prinseq]} -fastq {input} -stats_len -stats_info > {output}"

# TODO: include .gzipped fasta files in the above rule (or create second rule)
# TODO: histogram
# TODO: prokka (or cmsearch and prodigal)




