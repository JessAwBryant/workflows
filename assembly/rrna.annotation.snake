include: "../annotation/cmsearch.snake"
include: "../annotation/bwa.snake"

from python.common import get_file_name

# available rRNA DBs
rrna_db_dot_fmts=[]
from python.annotate import get_last_alg
for db, db_data in config.get('dbs',{}).items():
    if db_data.get('type') == 'rrna':
        fmt = db_data.get('format', 'lastdb')
        fmt = get_last_alg(fmt, 'fna')
        rrna_db_dot_fmts.append("{}.{}".format(db,fmt))

sample_coverages = \
        {s:"contigs.coverages.{sample}.txt".format(sample=s) \
                     for s in config['sample_data'] \
                     if 'clean' in config['sample_data'][s]}

id_names_files = {db: data['path'] + ".ids" \
                    for db, data in config['dbs'].items()}

def get_rna_search_hits(w):
    """ return search result that matches rmol (SSU or LSU) """
    for db_dot_fmt in rrna_db_dot_fmts:
        if re.search(w.rmol, db_dot_fmt):
            return ("contigs.vs.rRNA.cmsearch.{rmol}.gt{length}"
                     ".gff.vs.{db_dot_fmt}"
                   ).format(db_dot_fmt=db_dot_fmt,
                             length=w.length,
                             rmol=w.rmol)

wildcard_constraints:
    rmol=r'[LS]SU',
    length=r'\d+',

rule long_rrna_gff:
    """ find long LSU or SSU annotations """
    input:
        "{prefix}.gff"
    output:
        "{prefix}.{rmol}.gt{length}.gff"
    benchmark:
        "benchmarks/{prefix}.{rmol}.gt{length}.time"
    version:
        get_version("filter_blast_m8.py")
    shell:
        "grep {wildcards.rmol} {input} \
          | sort \
          | filter_blast_m8.py -s score -L {wildcards.length} -f gff \
            --nonoverlapping \
          > {output}"

rule rrna_fasta:
    """ extract rRNA fasta """
    input:
        fasta="{root}.fasta",
        gff="{root}.vs.{search}.gff"
    output:
        "{root}.vs.{search}.gff.fasta"
    benchmark:
        "benchmarks/{root}.vs.{search}.gff.fasta.time"
    version:
        get_version("get_sequences_from_m8.py")
    shell:
        "cat {input.fasta} \
            | get_sequences_from_m8.py -f gff {input.gff} \
            > {output}"

rule rrna_report:
    """
    Look at the rRNA annotations and get table of nearly full length LSUs or SSUs
    """
    input:
        gff="contigs.vs.rRNA.cmsearch.{rmol}.gt{length}.gff",
        hits=get_rna_search_hits,
        stats=sample_coverages.values(),
        id_names_files=id_names_files.values(),
    output:
        "contigs.vs.rRNA.cmsearch.{rmol}.gt{length}.tsv"
    run:
        # get map from contigs to coverage
        coverages = {}
        for sample, stats_file in sample_coverages.items():
            cov_table = pandas.read_table(stats_file,
                                          index_col=0,
                                          header=0,
                                         )
            coverages[sample] = cov_table[config['cov_col']]

        # table of rRNA model hits from filtered GFF
        features = pandas.read_table(get_file_name(input.gff),
                                     header=None,
                                     names=['contig',
                                            'tool',
                                            'type',
                                            'start',
                                            'end',
                                            'score',
                                            'notes'],
                                     usecols=[0,1,2,3,4,5,8])

        # add coverages for each sample
        coverage_col_names = []
        for sample, sample_covs in coverages.items():
            col_name = 'cov_{}'.format(sample)
            coverage_col_names.append(col_name)
            features[col_name] = \
                [sample_covs[features.loc[i,'contig']]\
                 for i in features.index]

        # index on contig, start, and end, and just take a few columns
        output_index_columns = ['contig', 'start', 'end']
        output_columns = coverage_col_names + ['type', 'score']
        output_table = features.set_index(output_index_columns)[output_columns]

        # get Silva annotation(s) for each feature
        from edl.blastm8 import generate_hits
        from edl.util import parseMapFile
        hit_table_name = re.search(r'gff\.vs\.(.+)', get_file_name(input.hits)).group(1)
        # should be, eg, SilvaSSU.lastn or SilvaSSU.bwa.sam
        words = hit_table_name.split('.')
        # first word is DB name
        db = words[0]
        # last word is fmt for parsing
        hit_format = words[-1]
        if hit_format.startswith('last'):
            hit_format = 'last'
        elif hit_format.startswith('blast'):
            hit_format = 'blastplus'
        hit_descriptions = parseMapFile(id_names_files[db])
        for gene, hits in generate_hits(get_file_name(input.hits), format=hit_format):
            # take the first hit
            hit = list(hits)[0]
            contig, start, end = re.search(r'^(.+)_(\d+)_(\d+)$', gene)\
                                                                    .groups()
            index = (contig, int(start), int(end))
            if index not in output_table.index:
                index = (contig, int(end), int(start))
            desc = hit_descriptions[hit.hit]
            output_table.loc[index, db] = desc

        output_table.to_csv(output[0], sep='\t')
