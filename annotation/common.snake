
rule hmmer_dbfrag:
    """
    Look for profile matches in the Nth fragment of a DB
    """
    input:
        "{file_root}.faa"
    output:
        temp("{file_root}.vs.{db}.{N}.tbl.dfrag")
    benchmark:
        "benchmarks/hmmer.{file_root}.vs.{db}.{N}.time"
    log:
        "logs/hmmer.{file_root}.vs.{db}.{N}.log"
    version:
        get_version('hmmsearch','-h',lines=[1,])
    threads:
        lambda wildcards: config['threads'].get('hmmer',default_threads)
    params:
        db_path=lambda wildcards: config['dbs'][wildcards.db]['path'].format(N=int(wildcards.N))
    shell:
        "hmmsearch --cpu {threads} --domtblout {output} -o /dev/null \
        {params.db_path} {input}"

rule hmmer_fragdb:
    """
    Look for profile matches in N fragments of a larger db. This rule just merges the N outputs of hmmer_dbfrag.
    """
    input:
        lambda w: expand("{file_root}.vs.{db}.{{N}}.tbl.dfrag".format(db=w.db,
                                                                      file_root=w.file_root), 
                         N=range(1,1+config['dbs'][w.db]['frags']))
    output:
        "{file_root}.vs.{db}.tbl.dbatch"
    benchmark:
        "benchmarks/hmmer.{file_root}.vs.{db}.dbatch.time"
    log:
        "logs/hmmer.{file_root}.vs.{db}.dbatch.log"
    version:
        get_version('sort',lines=[1,])
    shell:
        "cat {input} | grep -v '^#' | sort -k 1,1 > {output}"

rule hmmer:
    """
    Look for profile matches
    """
    input:
        "{file_root}.faa"
    output:
        "{file_root}.vs.{db}.tbl"
    benchmark:
        "benchmarks/hmmer.{file_root}.vs.{db}.time"
    log:
        "logs/hmmer.{file_root}.vs.{db}.log"
    version:
        get_version('hmmsearch','-h',lines=[1,])
    threads:
        lambda wildcards: config['threads'].get('hmmer',default_threads)
    params:
        db_path=lambda wildcards: config['dbs'][wildcards.db]['path']
    shell:
        "hmmsearch --cpu {threads} --domtblout {output} -o /dev/null \
        {params.db_path} {input}"

rule lastal:
    """
    Look for matches in RefSeq or KEGG
    """
    input:
        lambda w: "{file_root}.{ext}".format(file_root=w.file_root,
                ext="faa" if w.alg=='p' else 'fasta' if w.alg=='x' else 'ffn')
    output:
        "{file_root}.vs.{db}.last{alg,[xpn]}"
    benchmark:
        "benchmarks/lastal.{db}.time"
    log:
        "logs/lastal.{db}.log"
    version:
        get_version('lastal')
    threads:
        lambda wildcards: config['threads'].get('lastal',default_threads)
    params:
        db_path=lambda w: config['dbs'][w.db]['path'],
        fshift=lambda w: "-F 15" if w.alg=='x' else "",
        opts=lambda w: "" if w.alg=='n' else "-b 1 -x 15 -y 7 -z 25",
        keep=config.get('last_filter','-F 5')
    shell:
        "lastal -P {threads} {params.fshift} -f BlastTab {params.opts} \
         {params.db_path} {input} \
         | grep -v '^#'  \
         | filter_blast_m8.py -f blast {params.keep} \
         > {output}"

rule assign_taxa:
    """
    Turn a hit table of reads vs RefSeq into a table of read taxon assignments
    """
    input:
        "{prefix}.vs.{db}.{lastalg}"
    output:
        temp("{prefix}.annot.{db}.{lastalg,(last[nxp]|sam)}.{rank,[^.]+}.tsv")
    benchmark:
        "benchmarks/{prefix}.assign_taxa.{rank}.{db}.{lastalg}.time"
    params:
        taxdump=lambda w: os.path.split(config['dbs'][w.db]['path'])[0],
        taxmap=lambda w: config['dbs'][w.db]['path'] + ".tax",
        format=lambda w: 'blast' if re.search(r'^b?last[pnx]$', w.lastalg)\
                                 else w.lastalg
    version:
        get_version('assign_taxa.py')
    shell:
         "cat {input} \
         | assign_taxa.py -o {output} -r {wildcards.rank} \
            -f {params.format} -F 0 -C first -p accs \
            -n {params.taxdump} -m {params.taxmap}"

rule assign_paths:
    """
    Turn a hit table (from hmmer or lastal) into a one-to-many map from reads to gene families.
    """
    input:
        "{prefix}.vs.{db}.{ext}"
    output:
        temp("{prefix}.annot.gene_family.{db,[^.]+}.{ext}.tsv")
    benchmark:
        "benchmarks/{prefix}.assign_paths.{db}.time"
    log:
        "logs/{prefix}.assign_paths.{db}.log"
    version:
        get_version('assign_paths.py')
    params:
        format=lambda w: 'hmmsearchdom' if re.search(r'^tbl\b',w.ext) \
                                        else 'blast',
        # KEGG and PFAM need special handling
        params=lambda w: get_db_assignment_params(w, config),
        # Filter reading frame suffixes if translated with transeq
        filter = lambda w: translation_filter \
                                if re.search(r'nocolon\.sixframe',w.prefix) \
                                else "cat",
    shell:
         "cat {input} \
          | {params.filter} \
          | assign_paths.py -C first -f {params.format} {params.params} \
            -o {output}"

rule count_tax_hits:
    input:
        "{hit_table_prefix}.annot.{db}.{alg}.{rank}.tsv"
    output:
        "{hit_table_prefix}.annot.{db}.{alg}.{rank}.count.tsv"
    benchmark:
        "benchmarks/{hit_table_prefix}.{db}.{alg}.{rank}.count.time"
    log:
        "logs/{hit_table_prefix}.{db}.{alg}.{rank}.count.log"
    version:
        get_version("count_hits.py")
    shell:
        "count_hits.py -v -i {input} -H 1 -a portion\
        > {output} 2> {log}"

