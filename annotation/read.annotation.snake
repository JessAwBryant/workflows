# Python makefile to pull out reads from a BAM alignment 
#  and use RefSeq, KEGG, PFAM, and others to annotate them
# Annotations are generated as tables of gene_family counts 
#  groupbed by taxonomic clade
import sys
import os
snakefile_path=os.path.dirname(os.path.abspath(workflow.snakefile))
sys.path[0]=os.path.join(snakefile_path,'..','python')
from common import get_version

#########
# CONFIGURATION
#
# defaults for basic operation
config.setdefault('annotation_hit_table_map',{})
# create reads.fasta from reads.vs.contigs.bam unless something else is set
bam_file_prefix_map=config.setdefault('bam_file_prefix_map',{})
default_annotation_prefix = config.get('annotation_prefix','reads')
bam_file_prefix_map.\
    setdefault(default_annotation_prefix,
               '{}.vs.contigs.bam'.format(default_annotation_prefix))

# create maps back and forth between annotation and hit table prefixes
config['hit_table_map']={}
for prefix in bam_file_prefix_map:
    config['annotation_hit_table_map'].setdefault(prefix,prefix+".genes")
    config['hit_table_map'][config['annotation_hit_table_map'][prefix]]=prefix
#
# filter for assigment (so we count reads instead of genes)
config['hit_table_filter']="sed -r 's/^(S+)_\d+(\s+#)/\1\2/'"
#
# End configuration
##########

include: "../common/common.snake"
include: "./common.snake"

# make sure read extraction comes from sam, not a nonexistent fastq:
ruleorder: extract_reads > fastq_to_fasta

##########
# RULES:
#  This lays out the dependencies and logic of the workflow
#  After the "all" target, it is generally laid out start to finish
rule all:
    input:
        expand("{prefix}.annotation.{clade_rank}.{db}.tsv",
                db=gene_family_dbs,
                prefix=config['bam_file_prefix_map'],
                clade_rank=config['clade_ranks'],
                ),
        expand("{reads}.fasta.stats", reads=config['bam_file_prefix_map']),
        expand("{hit_table_prefix}.faa.stats",
               hit_table_prefix=config['hit_table_map'])

rule extract_reads:
    """
    Pull reads out of BAM file
    """
    input:
        lambda w: bam_file_prefix_map.get(w.annotation_prefix,
                                                    w.annotation_prefix)
    output:
        "{annotation_prefix}.fasta"
    benchmark:
        "benchmarks/extract_reads.time"
    log:
        "logs/extract_reads.log"
    version:
        get_version('samtools', lines=[0,])
    shell:
        "samtools fasta -0 {output} {input} > {log} 2>&1"

rule predict_genes_prodigal:
    """
    Generate FAA (fasta of amino acid sequences) for genes predicted in reads
    """
    input:
        lambda w: "{reads}.fasta".format(reads=config['hit_table_map'][w.hit_table_prefix])
    output:
        faa="{hit_table_prefix}.faa"
    log:
        "logs/{hit_table+prefix}.predict_genes_prodigal.log"
    benchmark:
        "benchmarks/{hit_table+prefix}.predict_genes_prodigal.time"
    version:
        get_version('batch_launcher.py') + '::' + \
        get_version('prodigal','-v')
    threads:
        config['threads'].get('prodigal',default_threads)
    shell:
        # Use batch launcher to multithread prodigal
        "batch_launcher.py -N {threads} -i -i -o -a -T fasta -X local -v -- \
         prodigal -i {input} -a {output} -p meta -q -o /dev/null > {log} 2>&1 "

rule clean:
    """ remove all generated files """
    params:
        anns=" ".join(expand("{annotation_prefix}.annotation.*",
                    annotation_prefix=config['bam_file_prefix_map'].values())),
        hits=" ".join(expand("{hit_table_prefix}.*",
                    hit_table_prefix=[config['annotation_hit_table_map'].get(a) for a in config['bam_file_prefix_map'].values()]))
    shell:
        "rm -rf logs benchmarks reads.fasta {params.anns} {params.hits}"

