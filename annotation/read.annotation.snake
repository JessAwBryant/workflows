# Python makefile to pull out reads from a BAM alignment 
#  and use RefSeq, KEGG, PFAM, and others to annotate them
# Annotations are generated as tables of gene_family counts 
#  groupbed by taxonomic clade
configfile: "annotation.yaml"
import sys
import os
snakefile_path=os.path.dirname(os.path.abspath(workflow.snakefile))
sys.path[0]=os.path.join(snakefile_path,'..','python')
from common import get_version
from annotate import get_db_assignment_params,get_db_types,\
                     get_hit_table_name_from_wildcards_db

#########
# CONFIGURATION
#
# bam file to start from
bam_file_with_reads=config.get('bam_file','reads.vs.contigs.bam')
#
# naming roots
# source file is genes.faa and hit tables are genes.vs.XXX.ext
config.setdefault('hit_table_prefix',"reads.genes")
config.setdefault('annotation_prefix','reads')
#
# rank to collect taxa on (defaults to order)
config.setdefault('clade_rank', 'order')
#
# threads per search are set in the threads: parameter
# Either use the db name or "default". EG:
# threads:
#   default: 5
#   lastal: 20
#   prodigal:   10
# Defaults to 8 for eveerything
default_threads=config.setdefault('threads',{}).get('default', 3)
#
# pull out taxdb (usually refseq) and list of gene family dbs
gene_family_dbs, config['taxdb'] = get_db_types(config)
#
mgorfs=snakefile_path + "/mgorfs.pl"
#
# filter for assigment (so we count reads instead of genes)
config['hit_table_filter']="sed -r 's/^(S+)_\d+(\s+#)/\1\2/'"
#
#
# End configuration
##########

include: "../common/common.snake"
include: "./common.snake"

##########
# RULES:
#  This lays out the dependencies and logic of the workflow
#  After the "all" target, it is generally laid out start to finish
rule all:
    input:
        expand("{annotation_prefix}.annotation.{clade_rank}.{{db}}.tsv".format(**config), 
                db=gene_family_dbs),
        "reads.fasta.stats",
        #"read_genes.mga.faa.stats",
        "{hit_table_prefix}.faa.stats".format(**config)

rule extract_reads:
    """
    Pull reads out of BAM file
    """
    input:
        bam_file_with_reads
    output:
        "reads.fasta"
    benchmark:
        "benchmarks/extract_reads.time"
    log:
        "logs/extract_reads.log"
    version:
        get_version('samtools', lines=[0,])
    shell:
        "samtools fasta -0 {output} {input} > {log} 2>&1"

rule predict_genes_prodigal:
    """
    Generate FAA (fasta of amino acid sequences) for genes predicted in reads
    """
    input:
        "reads.fasta"
    output:
        faa="{hit_table_prefix}.faa".format(**config)
    log:
        "logs/predict_genes_prodigal.log"
    benchmark:
        "benchmarks/predict_genes_prodigal.time"
    version:
        get_version('batch_launcher.py') + '::' + \
        get_version('prodigal','-v')
    threads:
        config['threads'].get('prodigal',default_threads)
    shell:
        # Use batch launcher to multithread prodigal
        "batch_launcher.py -N {threads} -i -i -o -a -T fasta -X local -v -- \
         prodigal -i {input} -a {output} -p meta -q -o /dev/null > {log} 2>&1 "

rule clean:
    """ remove all generated files """
    shell:
        "rm -rf logs benchmarks reads.fasta {annotation_prefix}.annotation.* {hit_table_prefix}.*".format(**config)

