configfile: "annotation.yaml"
import tempfile
# Python makefile to pull out reads from a BAM alignment 
#  and use RefSeq, KEGG, PFAM, and others to annotate them
# Annotations are generated as tables of gene_family counts 
#  groupbed by taxonomic clade

#########
# CONFIGURATION
#
# bam file to start from
bam_file_with_reads=config.get('bam_file','reads.vs.contigs.bam')
#
# rank to collect taxa on (defaults to order)
clade_rank=config.get('clade_rank', 'order')
#
# threads per search are set in the threads: parameter
# Either use the db name or "default". EG:
# threads:
#   default: 5
#   lastal: 20
#   prodigal:   10
# Defaults to 8 for eveerything
default_threads=config.setdefault('threads',{}).get('default', 3)
#
# pull out taxdb (usually refseq) and list of gene family dbs
gene_family_dbs = []
for db in config['dbs']:
    if config['dbs'][db].get('istaxdb',False):
        taxdb=db
    else:
        gene_family_dbs.append(db)
#
snakefile_path=os.path.dirname(os.path.abspath(workflow.snakefile))
mgorfs=snakefile_path + "/mgorfs.pl"
#
# End configuration
##########

#######
# Functions
import subprocess, re
def get_version(command, version_flag='--version', 
                cmd_prefix='',
                lines=None,
                regular_expression=None):
    """
    Gets the version string from a command

    cmd_prefix is useful if you need an interpreter (bash, python, etc)
    
    lines can be a line number (int), a slice object, or an iterable indicating which lines of the output to grab

    if regular_expression given, the first captured group is returned.
    """
    out = subprocess.check_output(" ".join([cmd_prefix,
                                            command,
                                            version_flag,
                                            "; exit 0"]),
                                  stderr=subprocess.STDOUT,
                                  shell=True).decode()

    # select specific lines
    if lines is not None:
        out_lines = out.split("\n")
        if isinstance(lines,slice):
            out = "\n".join(out_lines[lines])
        elif isinstance(lines, int):
            out = out_lines[lines]
        else:
            out = "\n".join(out_lines[i] for i in lines)

    # apply regular expression if given
    if regular_expression is None:
        return out.strip()
    else:
        return regular_expression.search(out).group(1)

def get_hit_table_name_from_wildcards_db(wildcards):
    """
    Return the hit table name based on the db name using the db config info
    """
    db=wildcards.db
    db_type=config['dbs'][db].get('type','hmmer')
    if db_type=='hmmer':
        if 'frags' in config['dbs'][db]:
            template = "read_genes.vs.{db}.tbl.dbatch"
        else:
            template = "read_genes.vs.{db}.tbl"
    elif db_type=='lastdb':
        template = "read_genes.vs.{db}.lastp"
    else:
        # Don't know what to do:
        raise Exception("Unknown database type for {}: {}".format(db,db_type))

    return template.format(**wildcards)

def get_db_assignment_params(wildcards):
    """
    return the params needed to turn hits from the given db (wildcards.db) into gene family assignments 
    using the assign_paths.py script
    """
    assign_type = config['dbs'][wildcards.db].get('assign_type','hitid').lower()
    if assign_type=='kegg':
        return '-p hitid -M kegg -m %s.kos' % (config['dbs'].get('KEGG',{'path':''})['path'])
    if assign_type=='pfam':
        return '-p pfam'
    return '-p hitid'
#
# End functions
##########


##########
# RULES:
#  This lays out the dependencies and logic of the workflow
#  After the "all" target, it is generally laid out start to finish
rule all:
    input:
        expand("reads.annotations.%s.{db}.tsv" % (clade_rank), 
                db=gene_family_dbs),
        "reads.fasta.stats",
        #"read_genes.mga.faa.stats",
        "read_genes.prodigal.faa.stats"

rule extract_reads:
    """
    Pull reads out of BAM file
    """
    input:
        bam_file_with_reads
    output:
        "reads.fasta"
    benchmark:
        "benchmarks/extract_reads.time"
    log:
        "logs/extract_reads.log"
    version:
        get_version('samtools', lines=[0,])
    shell:
        "samtools fasta -0 {output} {input} > {log} 2>&1"

rule prinseq_any:
    """
    calculate basic stats for a fasta or fastq file, gzipped or not 
    """
    input:
        "{file_root}.{ext}"
    output:
        "{file_root}.{ext,f.+}.stats"
    log:
        # complicated lmbda to handle different input types
        lambda wildcards: "logs/{file_root}.{ext}.stats.log"\
                            .format(file_root=re.sub(r'/','_',\
                                                     wildcards.file_root),
                                    ext=wildcards.ext)
    params:
        # use "ext" wildcard to set sequence format (fasta or fastq)
        input_flag=lambda wildcards:"-fastq" \
         if re.search(r'q',wildcards.ext) else "-fasta",
        # use -aa for .faa or .faa.gz files
        aa=lambda wildcards:"-aa" \
         if re.search(r'\bfaa\b',wildcards.ext) else "",
        # uncompress ".gz" files
        cat=lambda wildcards:"gunzip -c" \
         if re.search(r'\.gz$',wildcards.ext) else "cat"
    benchmark:
        "benchmarks/prinseq_{file_root}_{ext}.time"
    version:
        get_version('prinseq-lite.pl','-version')
    shell:
        "{params.cat} {input} | \
        prinseq-lite.pl {params.input_flag} stdin \
         -stats_len -stats_info {params.aa} > {output}"

rule predict_genes_prodigal:
    """
    Generate FAA (fasta of amino acid sequences) for genes predicted in reads
    """
    input:
        "reads.fasta"
    output:
        faa="read_genes.prodigal.faa"
    log:
        "logs/predict_genes_prodigal.log"
    benchmark:
        "benchmarks/predict_genes_prodigal.time"
    version:
        get_version('batch_launcher.py') + '::' + \
        get_version('prodigal','-v')
    threads:
        config['threads'].get('prodigal',default_threads)
    shell:
        # Use batch launcher to multithread prodigal
        "batch_launcher.py -N {threads} -i -i -o -a -T fasta -X local -v -- \
         prodigal -i {input} -a {output} -p meta -q -o /dev/null > {log} 2>&1 "

rule predict_genes_mga:
    """
    Generate FAA (fasta of amino acid sequences) for genes predicted in reads
    """
    input:
        "reads.fasta"
    output:
        faa="read_genes.mga.faa"
    benchmark:
        "benchmarks/predict_genes_mga.time"
    version:
        get_version('batch_launcher.py') + '::' + \
        "mga + mgorfs (unversioned)"
    log:
        "logs/predict_genes_mga.log"
    threads:
        config['threads'].get('mgorfs',default_threads)
    shell:
        "batch_launcher.py -N {threads} -i -i -o -A -T fasta -X local -v -- \
         {mgorfs} -i {input} -A {output}"

rule hmmer_stmp:
    """
    Look for profile matches, but copy everything to /tmp first
    """
    input:
        rules.predict_genes_prodigal.output.faa
    output:
        "read_genes.vs.{db}.tbl.stmp"
    benchmark:
        "benchmarks/hmmer.{db}.stmp.time"
    log:
        "logs/hmmer.{db}.stmp.log"
    version:
        get_version('hmmsearch','-h',lines=[1,])
    threads:
        lambda wildcards: config['threads'].get('hmmer',default_threads)
    params:
        db_path=lambda wildcards: config['dbs'][wildcards.db]['path'],
        tmp_dir=tempfile.TemporaryDirectory(suffix=None, prefix=None, dir='/mnt/stmp')
    shell:
        """
        for F in {params.db_path}.*; do cp $F {params.tmp_dir.name}/hmm.${{F##*.}}; done
        cp {input} {params.tmp_dir.name}/input
        hmmsearch --cpu {threads} --domtblout {output} -o /dev/null \
        {params.tmp_dir.name}/hmm {params.tmp_dir.name}/input
        """

rule hmmer_tmp:
    """
    Look for profile matches, but copy everything to /tmp first
    """
    input:
        rules.predict_genes_prodigal.output.faa
    output:
        "read_genes.vs.{db}.tbl.tmp"
    benchmark:
        "benchmarks/hmmer.{db}.tmp.time"
    log:
        "logs/hmmer.{db}.tmp.log"
    version:
        get_version('hmmsearch','-h',lines=[1,])
    threads:
        lambda wildcards: config['threads'].get('hmmer',default_threads)
    params:
        db_path=lambda wildcards: config['dbs'][wildcards.db]['path'],
        tmp_dir=tempfile.TemporaryDirectory(suffix=None, prefix=None, dir='/tmp')
    shell:
        """
        for F in {params.db_path}.*; do cp $F {params.tmp_dir.name}/hmm.${{F##*.}}; done
        cp {input} {params.tmp_dir.name}/input
        hmmsearch --cpu {threads} --domtblout {output} -o /dev/null \
        {params.tmp_dir.name}/hmm {params.tmp_dir.name}/input
        """

rule hmmer_dbfrag:
    """
    Look for profile matches in the Nth fragment of a DB
    """
    input:
        rules.predict_genes_prodigal.output.faa
    output:
        "read_genes.vs.{db}.{N}.tbl.dfrag"
    benchmark:
        "benchmarks/hmmer.{db}.{N}.time"
    log:
        "logs/hmmer.{db}.{N}.log"
    version:
        get_version('hmmsearch','-h',lines=[1,])
    threads:
        lambda wildcards: config['threads'].get('hmmer',default_threads)
    params:
        db_path=lambda wildcards: config['dbs'][wildcards.db]['path'].format(N=int(wildcards.N))
    shell:
        "hmmsearch --cpu {threads} --domtblout {output} -o /dev/null \
        {params.db_path} {input}"

rule hmmer_fragdb:
    """
    Look for profile matches in N fragments of a larger db. This rule just merges the N outputs of hmmer_dbfrag.
    """
    input:
        lambda w: expand("read_genes.vs.{db}.{{N}}.tbl.dfrag".format(db=w.db), 
                         N=range(1,1+config['dbs'][w.db]['frags']))
    output:
        "read_genes.vs.{db}.tbl.dbatch"
    benchmark:
        "benchmarks/hmmer.{db}.dbatch.time"
    log:
        "logs/hmmer.{db}.dbatch.log"
    version:
        get_version('sort',lines=[1,])
    shell:
        "cat {input} | grep -v '^#' | sort -k 1,1 > {output}"

rule hmmer:
    """
    Look for profile matches
    """
    input:
        rules.predict_genes_prodigal.output.faa
    output:
        "read_genes.vs.{db}.tbl"
    benchmark:
        "benchmarks/hmmer.{db}.time"
    log:
        "logs/hmmer.{db}.log"
    version:
        get_version('hmmsearch','-h',lines=[1,])
    threads:
        lambda wildcards: config['threads'].get('hmmer',default_threads)
    params:
        db_path=lambda wildcards: config['dbs'][wildcards.db]['path']
    shell:
        "hmmsearch --cpu {threads} --domtblout {output} -o /dev/null \
        {params.db_path} {input}"

rule lastal:
    """
    Look for matches in RefSeq for predicted genes
    """
    input:
        rules.predict_genes_prodigal.output.faa
    output:
        "read_genes.vs.{db}.lastp"
    benchmark:
        "benchmarks/lastal.{db}.time"
    log:
        "logs/lastal.{db}.log"
    version:
        get_version('lastal')
    threads:
        lambda wildcards: config['threads'].get('lastal',default_threads)
    params:
        db_path=lambda wildcards: config['dbs'][wildcards.db]['path']
    shell:
        "lastal -P {threads} -f BlastTab -b 1 -x 15 -y 7 -z 25 \
         {params.db_path} {input} > {output}"

# remove gene suffixes, so we are counting reads
# for prodigal
strip_gene_numbers_with_sed="sed -r 's/^(S+)_\d+(\s+#)/\1\2/'"
# for mga/mgorfs
#strip_gene_numbers_with_sed="sed -r 's/^(S+)_GENE_\d+\b/\1/'"

rule assign_taxa:
    """
    Turn a hit table of predicted genes vs RefSeq into a table of reads

    Uses sed to change gene names back into read names before the assignment script sets to work.
    """
    input:
        "read_genes.vs.{}.lastp".format(taxdb)
    output:
        "reads.annotations.taxon_rank.{rank}.tsv"
    benchmark:
        "benchmarks/assign_taxa.{rank}.time"
    log:
        "logs/assign_taxa.{rank}.log"
    params:
        taxdump=os.path.split(config['dbs'][taxdb]['path'])[0],
        taxmap=config['dbs'][taxdb]['path'] + ".tax"
    version:
        get_version('assign_taxa.py')
    shell:
         "cat {input} \
         | {strip_gene_numbers_with_sed} \
         | assign_taxa.py -o {output} -r {wildcards.rank} \
            -f blast -F 0 -C first -p accs \
            -n {params.taxdump} -m {params.taxmap}"

rule assign_paths:
    """
    Turn a hit table (from hmmer or lastal) into a one-to-many map from reads to gene families.

    Uses sed to change gene names back into read names before the assignment script sets to work.
    """
    input:
        #"read_genes.vs.{db}.tbl"
        # function that returns search result file name based on DB name
        get_hit_table_name_from_wildcards_db
    output:
        "reads.annotations.gene_family.{db}.tsv"
    benchmark:
        "benchmarks/assign_paths.{db}.time"
    log:
        "logs/assign_paths.{db}.log"
    version:
        get_version('assign_paths.py')
    params:
        format=lambda w: 'blast' if config['dbs'][w.db].get('type','hmm')=='lastdb' else 'hmmsearchdom',
        # KEGG and PFAM need special handling
        params=get_db_assignment_params
    shell:
         "cat {input} \
         | {strip_gene_numbers_with_sed} \
         | assign_paths.py -o {output} -C first -f {params.format} {params.params} \
         "

rule compile_counts:
    """
    Use clade assignments and gene family assignments to compile a table of gene family counts by clade.
    """
    input:
        rules.assign_taxa.output,
        rules.assign_paths.output
    output:
        "reads.annotations.{rank}.{db}.tsv"
    benchmark:
        "benchmarks/compile_counts.{rank}.{db}.time"
    log:
        "logs/compile_counts.{rank}.{db}.log"
    version:
        get_version('compile_hit_counts.py')
    params:
        three_column_opt="-L" if config.get('output_style','default').lower() == 'long' else ""
    shell:
        "compile_hit_counts.py {params.three_column_opt} -1 {input[0]} -2 {input[1]} -o {output} -S "

rule clean:
    """ remove all generated files """
    shell:
        "rm -rf logs benchmarks spades reads.fasta reads.annotations.* read_genes.*"

